<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Linking CSS -->
  <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css" integrity="sha384-9gVQ4dYFwwWSjIDZnLEWnxCjeSWFphJiwGPXr1jddIhOegiu1FwO5qRGvFXOdJZ4" crossorigin="anonymous">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/animate.css@3.5.2/animate.min.css">
  <link rel="stylesheet" type="text/css" href="styles/main.css">
  <link rel="apple-touch-icon" sizes="57x57" href="images/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="images/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="images/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="images/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="images/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="images/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="images/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="images/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="images/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="images/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="images/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
  <link rel="manifest" href="images/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="images/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Linking Javascripts -->
  <script
  src="https://code.jquery.com/jquery-3.3.1.js"
  integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60="
  crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js" integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.0.11/handlebars.js"></script>
  <script type="text/javascript" src="javascripts/main.js"></script>
  <script src="javascripts/smooth-scroll.js"></script>


  <title>Harman MHCI Capstone</title>
</head>
<body>

  <div id="navbar">
    <nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top" id="top">
      <div class="container">
        <a class="navbar-brand" href="index.html">MHCI x HARMAN</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <!-- Right Nav Content -->
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="background.html">CONTEXT</a>
            </li>
            <li class="nav-item dropdown active">
              <a class="nav-link dropdown-toggle" href="research.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                RESEARCH
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                <a class="dropdown-item" href="research.html">EXPLORATORY</a>
                <a class="dropdown-item" href="user_research.html">USER RESEARCH</a>
                <a class="dropdown-item active" href="research_documentation.html">FULL DOCUMENTATION</a>
              </div>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="design.html">DESIGN</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="team.html">THE TEAM</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="https://mhciharman.wordpress.com/">BLOG</a>
            </li>
          </ul>
        </div>

      </div>
    </nav>
  </div>

  <div class="container animated fadeIn">
    <div class="row">
      <div class="position-fixed">
        <div class="col-lg-12">
        <h1 class="animated fadeIn uppercase">FULL<br/>RESEARCH<br/>DOCS</h1>
        <a href="#research_preface">Research Preface</a>
        <br/>
        <a href="#secondary_research">Secondary Research</a>
        <br/>
        <a href="#av_users">Users of Autonomous Vehicles</a>
        <br/>
        <a href="#major_players">Major Players</a>
        <br/>
        <a href="#questions">Questions</a>
        <br/>
        <a href="#research_plan">Research Plan</a>
        <br/>
        <a href="#primary_research">Primary Research</a>
        <br/>
        <a href="#data_analysis">Data Analysis</a>
        <br/>
        <a href="#form_ut">Form User Testing</a>
        <br>
        <a href="#paper_ut">Paper Interaction User Testing</a>
        <br/>
        <a href="#digital_ut">Digital Interaction User Testing</a>
    </div>
      </div>
      <div class="col-lg-9 offset-lg-3" id="research_preface">
        <div class="row inner-row">
        <h2>Research Preface</h2>
        <p>
          To kick off the Capstone project experience, our team began by first seeking to balance our understanding of the autonomous vehicle (AV) space. One concern for us from the start was that some members of the team have worked in some capacity with the car or AV space, such as through an independent study or from full-time positions before the program. We wanted everyone on the team to be as equally educated in the AV space as possible to prevent any unnecessary dependencies moving forward.
        </p>

        <p>
          We familiarized ourselves about the levels of autonomous driving ranging from 0 to 5, with 0 being non-autonomous, 3 being Uber’s mixed initiative pilots, and 5 being fully autonomous, as well as the challenges of each. This helped ground us to the realism of the AV space in the near future, with better expectations that a “living room on wheels” is not viable anytime soon. Since the idea of complete, level-5 autonomy is not viable for at least five to ten years, our team decided to focus on a sooner reality, settling for level-3 mixed initiative since it offers also a unique opportunity to examine the handoff/takeover opportunities between the driver and the vehicle.
        </p>
        <p>
          We also read into some of the infrastructural ideas being tossed around, such as the idea of a “Smart Crosswalk” or a “Smart City” and how the AV landscape was hoping to leverage some capabilities of the physical environment surrounding it. After some consideration, however, we later decided that the concept of smart cities would be out of scope for us, since we cannot easily depend on infrastructure and policy to be supportive as of now.  Our interest in focusing on a more immediate reality further strengthened our decision to focus on level-3 autonomy.
        </p>
    </div>
    <hr/>
    <div class="row inner-row" id="secondary_research">
      <h2>Secondary Research</h2>
        <p>
          The team conducted a great deal of secondary research and literature review during the first 1.5 months of the project.  This dive into existing research helped us learn about the autonomous vehicle space, both its current state and speculated future.  Our readings delved into a multitude of areas, ranging everywhere from the ethics of AV passenger responsibility, to implementations of augmented reality displays in AVs.  However, our most revisited and essential research assets were largely made up of:
          <ul>
            <li>Studies examining the desired user experience of AVs</li>
            <li>Identification and desires of target users of AVs</li>
            <li>Activities of major players in the AV space</li>
          </ul>
        </p>
      </div>
      <div class="row inner-row">
      <h3>User Experience of Autonomous Vehicles</h3>
      <p>
        Due to the incomplete and unfinished technological development of AVs, it probably won’t come as a surprise that there has not yet been enough attention given to the user experience of autonomous vehicles.  However, we did find a handful of studies outlining some of the largest problem areas at hand.
      </p>
      <p>
        Trust of the vehicle is one of the most prominent issues facing human interaction with AVs.  Suggested solutions to this include providing the driver with some choice over navigation despite the automated GPS system, ensuring that the user can interact with an AV in a straightforward and flexible manner, and having the car clearly express its reliability to the user in a method of communication that they can easily understand.
      </p>
      <p>
        Many sources have expanded on this last point, citing transparency as an integral tool for increasing user trust.  One study looked at what kind of transparency is most advantageous, and found that there’s a delicate balance of providing enough information to put the driver at ease, but not so much that it overloads or leads to overreliance.  More specifically, this study found that telling the user why the car is doing something provides this desired information balance, but if focus is instead on telling the user what the car is going to do, this leads to overtrust of the system and poor takeover of the vehicle when necessary.  Overreliance is a prominent safety issue in the AV space as it leads to poor supervision and takeover, which are still highly necessary with the current level of AV technology.
      </p>
      <p>
        The team also came across the concept of strategic distraction during our research.  One study by Wendy Ju found that users in an AV who were watching videos on an iPad performed better at takeover tasks than those who were just asked to supervise the AV system.  This demonstrated that a way of mediating overreliance on the automated system and disengagement from supervision responsibilities is to engage the user in a certain degree of distraction.  This researcher is also noteworthy as she provided the direct inspiration for our Wizard of Oz autonomous car set-up in our primary research phase.
      </p>
    </div>
    <div class="row inner-row">
      <h3>Learnings from current AV systems</h3>
      <p>
        We also encountered research on current AV systems and their limitations.  One study discussed how users of Tesla Autopilot complain of poor, spotty lane detection, and abrupt braking, acceleration, and deceleration.  Another Tesla study found unreliable handling of subtle and complex road conditions.  In addition, this paper discussed the importance of a co-driving system, in which the human must monitor the autonomous driving system and be available for takeover during AV failures of environment context.
      </p>
      <p>
        Another interesting finding was Waymo’s central UX principles for their autonomous driving system.  They emphasize four tenants: giving the driver the info they need, helping to anticipate future events, communicating the car’s response to events on the road to the user, and finally, helping passengers safely engage with the vehicle.  This demonstrates their consideration of transparency and an intuitive means of communication with the vehicle, which is also reflected in research mentioned previously.
      </p>
    </div>
    <hr/>
    <div class="row inner-row" id="av_users">
      <h2>Users of Autonomous Vehicles</h2>
      <p>
        Our team also strived to learn about the future target audience for fully-functioning, commercially-available AVs.  We found many theories revolving around the concept of a shared autonomy future, meaning that in the next couple decades we can expect wide adoption of autonomous ride-sharing vehicles as an alternative to car ownership.  A number of studies described the most likely adopters of this shared autonomy future to be young, urban, educated, tech-savvy, environmentally conscious people who currently do not have a strong desire to own cars due to their environment, and who use ride-share services now.  One study also mentioned that those most likely to own autonomous vehicles in the future, instead of opting for the shared autonomy model, are individuals who currently own vehicles and have not tried ride-share services.  This research provides some perspective for who our ideal demographics are to test our designs going forward.
      </p>
      <p>
        We also found a small amount of research on what people might want to do with the newfound free time that comes from AVs, as this is integral to the non-driving aspect of the AV user experience.  Unsurprisingly, we found that people want to do what they do already in many other travel contexts - talk to others, text and call friends and family, listen to music, daydream, eat and drink, and browse the internet.  This helps inform what facilitation of these activities we should provide, and also how we can leverage these desires in strategic distraction methods.
      </p>
    </div>
    <hr/>
    <div class="row inner-row" id="major_players">
      <h2>Major Players in the Autonomous Vehicle Domain</h2>
      <p>
        Our team also assembled some shared repositories for information regarding key companies in AV research and development. We focused on some of the efforts of external players, such as Waymo, Tesla, Uber, and more of the traditional car manufacturers below.
      </p>
    </div>
    <div class="row inner-row">
      <h3>Tesla Autopilot</h3>
      <p>
        The existing implementation of Tesla autopilot provides an approximately level-2 experience of autonomous driving. There exists a level of takeover and handover where the car is either in autopilot or not in autopilot. While is autopilot, the car is able to control speed (as in relative cruise control, being aware of distance to vehicles ahead) as well as lane positioning and can perform gradual turns and bends. An important note is that the Tesla vehicle, while in autopilot mode, does not observe stop signs or traffic lights: it simply rolls through. This can be concerning to a Tesla user in autopilot mode if they are unfamiliar with the system’s limitations and helps to foster a sense of danger to the user in autopilot mode. Tesla also has controls on the steering wheel for the driver to fine-tune the speed limits as well as tailing distance to the car ahead. Currently, these controls are implemented as knobs.
      </p>
    </div>
    <div class="row inner-row">
      <h3>Uber ATG</h3>
      <p>
        Uber is currently piloting its level-3 autonomous vehicles in several major cities in the United States (namely Pittsburgh, Phoenix, and the San Francisco bay area). Uber’s model of shared driving experiences remains, with the customer of the Uber service being simply a passenger in the vehicle while employees of Uber are drivers, engaging in takeover and handover with the vehicle. The vehicle features LIDAR technology atop the car, as well as a tablet interface within the back-seat area of the vehicle to portray vehicular transparency to the customer.
      </p>
    </div>
    <div class="row inner-row">
      <h3>Waymo</h3>
      <p>
        Waymo is operating in a similar space to Uber ATG, where they are providing an on-demand ridesharing service to customers involving approximately level-3 autonomous vehicles. Waymo allows for the user to initialize the ride, with a “Start Ride” button. Once the ride has started, Waymo also uses a tablet interface to convey information about the ride to the end user, such as a localized map and estimated time of arrival, but also information about the car itself (including what the car is detecting through its LIDAR, radar, sound, and other sensory technology). Furthermore, the car always affords the user the ability to pull over, with a “pull over” button displayed to the user. The goals for Waymo are to provide a clear interface for a passenger to understand more about the vehicle as well as interface with the vehicle.
      </p>
      <p> 
        From a functional perspective, Waymo and Uber are similar in their goals for the customer in a ridesharing experience. The technology is very similar as well, highlighted by a 2017 lawsuit in which Waymo will receive 0.34 percent of Uber’s equity, valued at $245 million.
      </p>
    </div>
    <div class="row inner-row">
      <h3>Concept Cars</h3>
      <p>
        With a history of engineering prowess, the traditional concept car companies also have a fair stake in the realm of autonomous vehicle technology. Note that the concept cars mainly focus on level-4 or 5 autonomy (with the exception of Audi, who is on the cusp of level-3 in production today).
      </p>
    </div>
    <div class="row inner-row">
      <h6>Audi</h6>
      <p>
        Audi has declared itself to be at the forefront of autonomous vehicle technology in commercial cars, and for good reason. In 2017, Audi unveiled its luxury A8 Sedan which features an “AI traffic jam pilot” in which the car can handle acceleration, braking, steering, and more under 37mph, so long as there is a physical barrier between the two sides of the highway. The key is that it would not require any driver attention in those moments. Audi has also claimed to have been partnering with Nvidia to sell level 4 AVs by 2020, however whether or not they are still on target remains to be seen.
      </p>
    </div>
    <div class="row inner-row">
      <h6>BMW/Rolls Royce/Renault</h6>
      <p>
        Luxury carmaker BMW is also looking to expand into the AV landscape, with an unveiling of a “living room on wheels” designed for the future of autonomous vehicles (level-5, full autonomy). The car itself does not feature a steering wheel or any traditional controls. Instead, it has a large television for entertainment, since attention would not be needed on the road. Rolls Royce is also approaching the full autonomous space as a living room on wheels. While neither has implemented above level-3 autonomy, BMW has some standard aspects of autonomous driving in its vehicles today (such as adaptive cruise control), but remains in research of level-5 autonomy.
      </p>
    </div>
    <hr/>
    <div class="row inner-row" id="questions">
      <h2>Questions</h2>
      <p>
        After completing secondary research and exploring exactly what is being accomplished in the field of autonomous vehicles, our team then sought to enumerate our personal questions surrounding the autonomous vehicle space in order to figure out both what we were interested in as a team, and any hierarchical structure that could arise. We performed a post-it note activity, where each member of the team wrote individual questions they had on post-it notes and then grouped alike questions on the board, leading to higher buckets to classify such information.
      </p>
      <p>
        We originally had over eighty questions which we decided to narrow down based on several limiting factors, such as:
        <ul>
          <li>Was this question (or grouping of questions) feasible with our technical abilities?</li>
          <li>Does this question (or grouping of questions) offshoot into political or ethical issues larger than what we feel we can accomplish in a few months?</li>
          <li>Is this question (or grouping of question) more focused on infotainment than the actual AV aspects of the car?</li>
        </ul>
        Below are our original labeled buckets of questions, with some additional information about each:
      </p>
      <br/>
      <div class="col-md-12">

        <br>
        <h3>Questions (By Topic)</h3>
        <br>
        <ul id="tabsJustified" class="nav nav-tabs">
            <li class="nav-item black-text"><a href="" data-target="#customization" data-toggle="tab" class="nav-link small text-uppercase active white-text grey">Customization</a></li>
            <li class="nav-item"><a href="" data-target="#enjoyment" data-toggle="tab" class="nav-link small text-uppercase white-text grey">Enjoyment</a></li>
            <li class="nav-item"><a href="" data-target="#personalization" data-toggle="tab" class="nav-link small text-uppercase white-text grey">Personalization</a></li>
            <li class="nav-item"><a href="" data-target="#takeover" data-toggle="tab" class="nav-link small text-uppercase white-text grey">Take Over</a></li>
            <li class="nav-item"><a href="" data-target="#trust" data-toggle="tab" class="nav-link small text-uppercase white-text grey">Trust</a></li>
            <li class="nav-item"><a href="" data-target="#surroundings" data-toggle="tab" class="nav-link small text-uppercase white-text grey">Surroundings</a></li>
            <li class="nav-item"><a href="" data-target="#control" data-toggle="tab" class="nav-link small text-uppercase white-text grey">Control</a></li>
        </ul>
        <br>
        <div id="tabsJustifiedContent" class="tab-content">
            <div id="customization" class="tab-pane fade active show">
                <p>
                  How do people wish to personalize their experience in an autonomous vehicle?  Is there some means by which an autonomous car can continue to reflect the people inside even if these people are not directly in control of the car at all times?<br>
                  Questions:
                  <ul>
                    <li>Is there any consistency between what people want inside and outside of the vehicle? Is everyone different?</li>
                    <li>To what extent is it a customizable ecosystem for each user?</li>
                    <li>Should we design for customization of the experience, or standardization?</li>
                    <li>In shared vehicles, should people have custom personalization?</li>
                  </ul>
                </p>
            </div>
            <div id="enjoyment" class="tab-pane fade">
                <p>
                  Considering the occupant will not be directly driving the vehicle at all times, how should we keep them engaged in the drive, if at all? What aspects of driving can we maintain from the existing driving experience to keep it exciting?<br>
                  Questions:
                  <ul>
                    <li>What are alternatives to the steering wheel?</li>
                    <li>Can autonomous driving be rewarding?</li>
                    <li>What will people miss about driving a car?</li>
                    <li>What do people like about driving?</li>
                    <li>What makes the current driver/car feel special about themselves (the hybrid subjectivity)?</li>
                  </ul>
                </p>
            </div>
            <div id="personalization" class="tab-pane fade">
                <p>
                  What kind of personal relationship do people want with an AV? How can we quantify what specific drivers might want to interact with the vehicle?<br>
                  Questions:
                  <ul>
                    <li>Do people want talking cars?</li>
                    <li>Is there an “uncanny valley” type of problem?</li>
                    <li>Why do people name cars?</li>
                    <li>Should cars have a voice?</li>
                    <li>Do cars have personalities?</li>
                    <li>Can cars be social?</li>
                    <li>Are cars a reflection of someone’s identity or personality?</li>
                    <li>Can a car be your friend?</li>
                    <li>Can cars be social facilitators?</li>
                    <li>Are AVs reflective of a master/servant relationship or peer/friend?</li>
                    <li>What do people expect of AV culture long-term?</li>
                  </ul>
                </p>
            </div>
            <div id="takeover" class="tab-pane fade">
                <p>
                  Considering a grey line surrounding when a user might need to control the vehicle versus autonomous technology, how can we facilitate a smooth transition experience between a driver and vehicle?<br>
                  Questions:
                  <ul>
                    <li>How can we perform handoff safely?</li>
                    <li>How might we create an approximate sense of fear in an AV?</li>
                    <li>What is the right level of attention?</li>
                    <li>How do we define “supervise”?</li>
                    <li>How do people feel about having a “hands on wheel” restriction?</li>
                    <li>Can I make a driving adjustment without taking over?</li>
                  </ul>
                </p>
            </div>
            <div id="trust" class="tab-pane fade">
                <p>
                  How can we improve the degree of trust an occupant has with the vehicle they are in?<br>
                  Questions:
                  <ul>
                    <li>When is trust important?</li>
                    <li>Does transparency improve trust?</li>
                    <li>How can we help someone trust a vehicle?</li>
                    <li>How might we calibrate trust?</li>
                    <li>How can we build rapport with a vehicle?</li>
                  </ul>
                </p>
            </div>
            <div id="surroundings" class="tab-pane fade">
                <p>
                  What are important elements of the surroundings that we should communicate to the user through the car, and how should this be communicated?<br>
                  Questions:
                  <ul>
                    <li>How can we convey the immediate space around a passenger?</li>
                    <li>What do people want to know about the outside world?</li>
                    <li>How much do passengers care about exterior vs interior actions?</li>
                  </ul>
                </p>
            </div>
            <div id="control" class="tab-pane fade">
                <p>
                  How do users wish to control an autonomous vehicle? What aspects of the drive would they like to tweak to have the car perform to their liking while in autopilot?<br>
                  Questions:
                  <ul>
                    <li>When do people want to control a car during a drive? Why?</li>
                    <li>How can a complex UI control complex driving tasks?</li>
                    <li>Will people want to override an AV?</li>
                    <li>What controls do people want in a mixed-initiative AV?</li>
                    <li>What do people want to adjust in an AV?</li>
                  </ul>
                </p>
            </div>
        </div>
      </div>
      <p>
        Organizing and prioritizing these questions helped us create a primary research plan going forward.
      </p>
    </div>
    <hr/>
    <div class="row inner-row" id="research_plan">
      <h2>Research Plan</h2>
      <p>
        Upon enumerating our list of motivating questions, our team set out to construct a research plan to dictate our efforts moving forward. We looked to combine our known research methods with our questions in a means that would best help narrow down what we would focus on. We also sought to prioritize questions that seemed more fundamental to a mixed-initiative vehicle experience.
      </p>
      <table class="table table-sm">
        <thead class="thead-dark">
          <tr>
            <th scope="col">Priority (1 being highest)</th>
            <th scope="col">Research Goals</th>
            <th scope="col">Research Topic</th>
            <th scope="col">Research Question</th>
            <th scope="col">Research Method</th>
            <th scope="col">Target Participants</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <th scope="row">1</th>
            <td>essential features/desired experience</td>
            <td>Passive Control</td>
            <td>What types of things do you want to control</td>
            <td>simulation think-aloud/post</td>
            <td>anybody</td>
          </tr>
          <tr>
            <th scope="row">1</th>
            <td>essential features/desired experience</td>
            <td>Passive Control</td>
            <td>What types of things do you want to control</td>            
            <td>Existing advanced autopilot interviews</td>
            <td>Tesla owners, people who have assisted driving in their vehicles</td>
          </tr>
          <tr>
            <th scope="row">1</th>
            <td>areas of opportunity</td>
            <td>Enjoyment</td>
            <td>What do people like and dislike about driving/automated driving?</td>            
            <td>Interview Extreme User Group</td>
            <td>enthusiasts; resistant parties</td>
          </tr>
          <tr>
            <th scope="row">1</th>
            <td>areas of opportunity</td>
            <td>Enjoyment</td>
            <td>What do people like about automated driving?</td>            
            <td>Expert interview - sales people, Harman stakeholders</td>
            <td>Tesla drivers; car salesmen, Harman</td>
          </tr>
          <tr>
            <th scope="row">1</th>
            <td>desired experience</td>
            <td>Enjoyment</td>
            <td>What do people like about manual driving?</td>            
            <td>Expert interview - sales people</td>
            <td>Car salesmen, anybody</td>
          </tr>
          <tr>
            <th scope="row">1</th>
            <td>areas of opportunity</td>
            <td>Trust</td>
            <td>How can we make people trust an autonomous vehicle in different situations? In what situations is a solution needed?</td>            
            <td>Co-design</td>
            <td>MHCI/anybody</td>
          </tr>
          <tr>
            <th scope="row">2</th>
            <td>desired experience</td>
            <td>Takeover</td>
            <td>What are optimal steps for a smooth transition?</td>
            <td>Co-Secondary research (Lit review VR)</td>
            <td></td>
          </tr>
          <tr>
            <th scope="row">2</th>
            <td>desired experience</td>
            <td>Takeover</td>
            <td>What are optimal steps for a smooth transition?</td>
            <td>Co-Secondary research (Lit review Autopilot)</td>
            <td></td>
          </tr>
          <tr>
            <th scope="row">2</th>
            <td>required features</td>
            <td>Takeover</td>
            <td>When do you want to take over control?</td>
            <td>Post-simulation interview</td>
            <td></td>
          </tr>
          <tr>
            <th scope="row">2</th>
            <td>desired experience</td>
            <td>Preferences</td>
            <td>What preferences of the in car experience change from person to person while being driven?</td>
            <td>Post-simulation interview</td>
            <td>anybody</td>
          </tr>
          <tr>
            <th scope="row">2</th>
            <td>essential features/desired experience</td>
            <td>Surroundings</td>
            <td>How do I want my surroundings represented to me and why?</td>
            <td>Co-design; post-simulation interview</td>
            <td>anybody</td>
          </tr>
          <tr>
            <th scope="row">3</th>
            <td>desired experience</td>
            <td>Personification</td>
            <td>What kind of personified relationship is desired?</td>
            <td>Storyboarding</td>
            <td>anybody</td>
          </tr>
          <tr>
            <th scope="row">3</th>
            <td>desired experience</td>
            <td>Personification</td>
            <td>What kind of personified relationship is desired?</td>
            <td>body storming</td>
            <td>anybody</td>
          </tr>
        </tbody>
      </table>
      <p>
        Considering our research method choices, we decided to broadened the range of techniques used to explore the domain in order to attack the AV space from as many angles as possible. We cared about first trying to learn all we could about the domain from experts or those involved with AVs right now (such as owners of Tesla vehicles with autopilot or car salespeople). We also recognized the importance of constructing our own simulations to help us better elicit user emotions. This immediately resulted in our Wizard of Oz study (WoZ).
      </p>
    </div>
    <!-- <a href="#top">Back to Top</a> -->
    <br/>
    <hr/>
    <div class="row inner-row" id="primary_research">
      <h2>Primary Research Methods</h2>
    </div>
    <div class="row inner-row">
      <h3>Wizard of Oz (WoZ)</h3>
      <p>
        In order to explore issues of the user’s sense of trust, safety, control, and enjoyment, we created a “Wizard of Oz” (WoZ) experiment simulating the experience of being a passenger in a self-driving car.  A real driver, obscured by a foam core divider, operated the vehicle at all times with the participant in the passenger seat.  We also had a facilitator in the backseat prompting the participant with questions and taking notes, in addition to cameras recording audio and visual information facing the participant and out the windshield.  Participants were given the impression that the driver was there for liability reasons and that the vehicle was operating itself.  Despite our simple set-up, majority of participants stated at the end of the study that they thought it was a fully-operating self-driving vehicle.
      </p>
      <img src="images/WoZ.png" class="img-fluid" alt="Responsive image">
      <p>
        Users were taken on a fixed loop route that included planned critical incidents like stop signs, navigating pedestrian-heavy intersections, and unprotected left turns, plus inevitable unplanned incidents like halted mail trucks and other cars blocking the road while parking.
      </p>
      <img src="images/course.png" class="img-fluid" alt="Responsive image">
      <p>
        Participants were instructed to “think aloud” during the entire drive, which is a self-explanatory user research technique used to find problem areas in a system.  The facilitator took notes on these comments, and prompted the user after every critical incident to describe what they expected and how they felt about the events that took place.  Our team conducted 11 of these WoZ experiments with a  quasi-representative sample of participants recruited from Carnegie Mellon University and Craigslist.
      </p>
    </div>
    <div class="row inner-row">
      <h3>Interviews</h3>
    </div>
    <div class="row inner-row">
      <h6>Tesla Interviews</h6>
      <p>
        We conducted phone interviews with eight Tesla owners to understand their experience with Tesla’s Autopilot system, which is the most advanced semi-autonomous driving system currently available.  These users represented our best access to the experience of autonomous car users, who don’t currently exist.
      </p>
      <p>
        Members of our team asked Tesla owners about reasons they like or dislike Tesla Autopilot, what driving situations make them uncomfortable, when they turn it on or off, and if they wish anything about the experience was different.
      </p>
    </div>
    <div class="row inner-row">
      <h6>Car Enthusiast Interviews</h6>
      <p>
        We also conducted interviews over the phone and in person with nine self-identified car enthusiasts to learn about what people love about driving, and how we might retain that enjoyment in an autonomous driving system.
      </p>
      <p>
        They were asked about their experience with cars, what they love about their current vehicles, their thoughts on the future of cars, and what they think about maintaining car culture in an increasingly autonomous future.
      </p>
    </div>
  <hr/>
  <div class="row inner-row" id="data_analysis">
    <h2>Data Analysis</h2>
  </div>
  <div class="row inner-row">
    <h3>Affinity Diagramming</h3>
    <p>
      After gathering all our interviews from Tesla drivers, car enthusiasts, and our WoZ participants, we set on the task of converting all this raw data into insights.  To do this, we conducted affinity diagramming, turning 1,100+ data points into a series of hierarchical groupings in order to uncover patterns in user comments.  Select different categories below to see overviews of our findings.  “I” statements represent the summarized sentiments of multiple users.
    </p>
    <div id="accordion" class="w-100">
      <div class="card">
        <div class="card-header" id="headingOne">
          <h5 class="mb-0">
            <button class="btn btn-link text-red" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
              Need for Human Intuition
            </button>
          </h5>
        </div>

        <div id="collapseOne" class="collapse show" aria-labelledby="headingOne" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>I’m so anxious about losing control that I want to be able to jump in.
                <ul>
                  <li>I was constantly double-checking the AV’s behavior.</li>
                  <li>I didn’t want to look away from the road in case I missed something that led to an accident.</li>
                  <li>I want to feel like I can takeover from autonomous mode at any time.</li>
                </ul>
              </li>
              <li>I will feel more comfortable when AV’s can reliably predict human behavior.
                <ul>
                  <li>There is an implicit culture surrounding human driving, such as hand signals or using horns, that may be tough to capture by an AV.</li>
                  <li>The AV needs to recognize human intent to be trustworthy - shapes in the environment aren’t enough.</li>
                  <li>Sometimes I or other drivers get uncomfortable when my car is in Autopilot and acts on measurements that are too precise, like a parking space that doesn’t look large enough, or hugging turns too tightly on the highway.</li>
                </ul>
              </li>
              <li>I don’t think AVs can handle dynamic driving as well as humans.
                <ul>
                  <li>I think I can drive the car better than an AV in difficult situations.</li>
                  <li>The technology is not developed enough to drive as well as a human.</li>
                  <li>There are too many edge cases on the road for the AV to handle them all safely and reliably.</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="card">
        <div class="card-header" id="headingTwo">
          <h5 class="mb-0">
            <button class="btn btn-link collapsed text-red" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
              Trust Grows with Familiarity
            </button>
          </h5>
        </div>
        <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>I’m fearful of tech that I don’t understand or am unfamiliar with.
                <ul>
                  <li>I didn’t feel in control of the car when it was an autonomous mode.</li>
                  <li>Being driven by an AV was a strange experience.</li>
                  <li>I want to know what the car is doing and how it’s making these decisions.</li>
                  <li>I feel powerless.</li>
                </ul>
              </li>
              <li>I become more trustful with AV tech as it performs well.
                <ul>
                  <li>I was a little uneasy using Autopilot at first, but I got more comfortable with it after more use.</li>
                  <li>The AV did better than I was expecting.</li>
                  <li>I’m not sure how the AV knew how to do that, but I’m glad it did.</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="card">
        <div class="card-header" id="headingThree">
          <h5 class="mb-0">
            <button class="btn btn-link collapsed text-red" data-toggle="collapse" data-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
              AV Driving Benefits
            </button>
          </h5>
        </div>
        <div id="collapseThree" class="collapse" aria-labelledby="headingThree" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>I’m fearful of tech that I don’t understand or am unfamiliar with.
                <ul>
                  <li>I appreciate how AVs are addressing the tedious parts of driving.</li>
                  <li>I wish I could use Autopilot on surface streets, not just highway.</li>
                  <li>AVs would be most helpful to me in commute traffic, and for long-distance driving.</li>
                </ul>
              </li>
              <li>I like that I don’t have to pay attention as much with AVs.
                <ul>
                  <li>I love being able to sit back and relax.</li>
                  <li>Using Autopilot lowers my stress, and actually increases my ability to monitor safety on the road.</li>
                  <li>Some people abuse Autopilot and don’t pay attention as much as they’re supposed to.</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="card">
        <div class="card-header" id="headingThree">
          <h5 class="mb-0">
            <button class="btn btn-link collapsed text-red" data-toggle="collapse" data-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
              Good UX as a Collection of Reassuring Moments
            </button>
          </h5>
        </div>
        <div id="collapseFour" class="collapse" aria-labelledby="headingFour" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>I want my AV to be situationally aware as it makes smart decisions for me.
                <ul>
                  <li>I want my tailing distance to be different depending on traffic and other factors.</li>
                  <li>I want the AV to be able to flexible in tough driving situations, like gridlock or yellow lights.</li>
                  <li>I want the AV to have common sense, and be empathetic towards others.</li>
                </ul>
              </li>
              <li>My trust with an AV is built in specific moments.
                <ul>
                  <li>I began trusting autonomous driving when it braked for me and prevented an accident.</li>
                  <li>I became more comfortable with the AV as it continued making cautious and correct driving decisions.</li>
                  <li>I trusted the AV more when it was more assertive in certain driving situations because it demonstrated capability.</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="card">
        <div class="card-header" id="headingThree">
          <h5 class="mb-0">
            <button class="btn btn-link collapsed text-red" data-toggle="collapse" data-target="#collapseFive" aria-expanded="false" aria-controls="collapseFive">
              Personalization
            </button>
          </h5>
        </div>
        <div id="collapseFive" class="collapse" aria-labelledby="headingFive" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>I want the AV to learn who I am and tailor itself to me.
                <ul>
                  <li>I liked that the AV drove like I would have just now.</li>
                  <li>It gets annoying when the AV drives more cautiously than I would.</li>
                  <li>I would not have gone there.</li>
                </ul>
              </li>
              <li>I want to shift the level of cautiousness/aggressiveness in my AV based on the situation.
                <ul>
                  <li>I’m okay with the AV’s quick maneuvers when it’s just me, but I want it to drive differently when my family is in the car.</li>
                  <li>When the car is in Autopilot, it drives too cautiously.</li>
                  <li>I turn off Autopilot when I want to drive more aggressively.</li>
                </ul>
              </li>
              <li>I make my car represent who I am.
                <ul>
                  <li>I think cars should be an extension of someone’s personality, including the way it drives.</li>
                  <li>I’m proud of my car and like to show it off.</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="card">
        <div class="card-header" id="headingThree">
          <h5 class="mb-0">
            <button class="btn btn-link collapsed text-red" data-toggle="collapse" data-target="#collapseSix" aria-expanded="false" aria-controls="collapseSix">
              Cars Mean More than just Transportation
            </button>
          </h5>
        </div>
        <div id="collapseSix" class="collapse" aria-labelledby="headingSix" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>My car is an integral part of my lifestyle.
                <ul>
                  <li>I need a car for my work commute.</li>
                  <li>I enjoy owning a car in the same way others like owning other personal possessions.</li>
                </ul>
              </li>
              <li>Directly controlling the car brings me joy.
                <ul>
                  <li>I equate driving with a sense of freedom.</li>
                  <li>I love to let my car loose and see what it can do.</li>
                </ul>
              </li>
              <li>The increasing prevalence of AVs is going to exclude my interests.
                <ul>
                  <li>I don’t think AVs can provide the sense of freedom I get from driving.</li>
                  <li>AVs would be good for some people, but not for me.</li>
                  <li>I don't have a use for AVs.</li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="card">
        <div class="card-header" id="headingThree">
          <h5 class="mb-0">
            <button class="btn btn-link collapsed text-red" data-toggle="collapse" data-target="#collapseSeven" aria-expanded="false" aria-controls="collapseSeven">
              Willing to Adopt AV ASAP
            </button>
          </h5>
        </div>
        <div id="collapseSeven" class="collapse" aria-labelledby="headingSeven" data-parent="#accordion">
          <div class="card-body">
            <ul>
              <li>I trust the AV enough to where I feel comfortable using personal tech without hesitation.
                <ul>
                  <li>I want to check social media when the AV is driving for me.</li>
                  <li>There are lots of ways I would like to interact with entertainment in an AV.</li>
                  <li>I want to use the free time I get from AVs to work and check my email.</li>
                </ul>
              </li>
              <li>I don’t have much hesitation about an AV driving me.
                <ul>
                  <li>I generally trust the AV to drive for me, except in extreme situations.</li>
                  <li>I use Autopilot whenever possible, and understand its limitations.</li>
                  <li>I’m confident that AVs would not be on the road if they couldn’t conduct all the basic driving functions.</li>
                </ul>
              </li>
              <li>AVs are better than human drivers.
                <ul>
                  <li>I feel safer in an AV than with a human driver because humans are not as analytically capable as machines.</li>
                  <li>Driving would be safer if everyone on the road was in an AV, driving in a standardized manner.</li>
                  <li>I would be more comfortable with AV technology if there were more of them on the road instead of humans.</li>
                </ul>
              </li>
              <li>I understand the benefit AVs bring to society.
                <ul>
                  <li>I assume AVs will be electric and better for the environment, as well as road safety.</li>
                  <li>If I don’t have to drive then I can bond more with my friends and family in the car.</li>
                </ul>     
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
  <br/>
  <!-- <a href="#research_preface">Back to Top</a> -->
  <br/>
  <div class="row inner-row">
    <h3>Affinity Diagramming</h3>
    <p>
      Based on our high-level groupings, our team identified six areas of exploration to take with us into the design phase. These were selected based upon the most supported findings in the data, problems that are currently unaddressed by other solutions, and finally what questions our team was most passionate about answering:
    </p>
  </div>
  <div class="row inner-row">
    <h6>The Moments that Build Trust</h6>
    <p>
      Users’ trust in the AV system increases based upon its performance in specific moments during the ride.  What are these moments, and how can we facilitate them?
    </p>
  </div> 
  <div class="row inner-row">
    <h6>Learning my Driving Preferences and Incorporating Feedback</h6>
    <p>
      Users want the AV to drive like they would.  How can users convey their driving preferences to the AV during the drive, and how should the vehicle acknowledge and incorporate this feedback?
    </p>
  </div>  
  <div class="row inner-row">
    <h6>Establishing Driver Agency</h6>
    <p>
      Users need reassurance that they have control over the vehicle, even when it is in autonomous driving mode.  How can we communicate that most effectively and make the user feel in control?
    </p>
  </div> 
  <div class="row inner-row">
    <h6>Personalized Interior Experiences</h6>
  </div>
  <div class="row inner-row">
    <p>
      Users want the car to recognize their desires and remember their preferences.  What specifically do users want or not want the car to do for them?
    </p>
  </div>     
  <div class="row inner-row">
    <h6>What to Make Transparent to the Driver</h6>
    <p>
      Users need the right amount of transparency into the workings of the AV system.  What is necessary to show,  what is too much, and how should this information be displayed?
    </p>
  </div> 
  <div class="row inner-row">
    <h6>Enjoyable Control of Autonomous Driving</h6>
  </div>
  <div class="row inner-row">
    <p>
      Users derive joy from controlling their vehicles.  How can this be retained in an AV system?
    </p>
  </div>
  <hr/>
  <div class="row inner-row" id="form_ut">
    <h2>Form User Testing</h2>
  </div>
  <div class="row inner-row">
    <h3>Form Testing | 6 MHCI Students</h3>
    <!-- Below image is a placeholder -->
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">All eight forms tested.</figcaption>
    </figure>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Example of S shape, with curves on top and bottom.</figcaption>
    </figure>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Example of J shape, with curve on bottom only.</figcaption>
    </figure>
    <h5>Protocol</h5>
    <p>
      Users were asked to discuss and rank their comfort and confidence using different shapes and sizes of physical controls for the use cases of speed, lane position adjustment, and two types of go/don’t go decisions (right on red and unprotected left).  Some were shown a subset emphasizing difference in shape and severity of curve, some were shown a subset emphasizing size, and some were shown all of them.  This test and all the following conducted for the remainder of the project was prefaced with an introduction to set the context for the user.  This stated that they were in a semi-autonomous vehicle, defined what that meant in terms of car options available and expected user responsibilities, and told them our control was a touch interface for expressing preferences to the car during autonomous driving mode.
    </p>
    <h5>Findings</h5>
    <p>
      <ul>
        <li>Users unanimously preferred a smaller size and an S shape, instead of larger sizes and a J or flat shape.</li>
        <li>Majority brought up wanting to minimize movement, preferred a slight curve as opposed to a more dramatic one, and mentioned wanting haptic feedback and applying a car pedal mental model.</li>
      </ul>
    </p>
  </div>
  <hr/>
  <div class="row inner-row" id="paper_ut">
    <h2>Paper Interaction User Testing</h2>
  </div>
  <div class="row inner-row">
    <h3>Realistic and Abstract Designs | 5 Craigslist Recruits with Driving Experience</h3>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Realistic Model.</figcaption>
    </figure>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Abstract model for speed/adjust in-lane (left) and binary (right).</figcaption>
    </figure>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Secondary screen image for decreasing speed.</figcaption>
    </figure>
    <h5>Design</h5>
    <p>
      These two designs were created to test if a more literal, realistic representation of the car’s movements was more appropriate for the control, or if people would understand and respond to a more abstract, joystick-like control.  In the Realistic design, there’s a distinct area for speed in the upper portion, and an area of lateral in-lane adjustment in the lower area, both of which require a swiping motion along the relevant axis of the control.  In the Abstract design, we had a squishable egg and ridges in cardinal directions around it to encourage the user to squish the object left or right for in-lane adjustment, or up and down for speed adjustment.  The idea was not there there would be an actual 3D object on the control, but that the digital version would have a shape that reacted in the same manner as the egg when touched.  These two designs were accompanied by a secondary screen showing feedback on what action they were performing, and representing that action with icons and minimal labels.
    </p>
    <h5>Protocol</h5>
    <p>
      Users were asked how they think they can interact with the control (affordances); how they would change their speed, lane position, and make a binary confirmation after being prompted by the secondary screen; and then provide feedback on the interactions that we had in mind.  This was done for both the Realistic and Abstract designs with each user.  These questions were administered while users sat in front of a driving simulator - see <a href="#testing_environment">Testing Environment</a> for more details on the simulator set-up.  At the end of each session, the user was also asked to rate their hand and arm comfort using the S shape compared to a flat shape.
    </p>
    <h5>Findings</h5>
    <ul>
      <li>All users thought the binary decision was confirmed by tapping the circle instead of sliding (before we explained our design intentions)</li>
      <li>4/5 maintained that they preferred to press a button instead of slide for binary (after explanation)</li>
      <li>4/5 liked the S shape better than the flat shape</li>
      <li>3/5 thought speed area might be forward and reverse, and were confused about lane change or turning for the lateral area (before explanation)</li>
      <li>3/5 wanted more information in general about speed and in-lane adjustment</li>
    </ul>
  </div>

  <div class="row inner-row">
    <h3>Separated and Consolidated Designs | 9 Craigslist recruits with driving experience</h3>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Separated design for speed and in-lane adjustment.</figcaption>
    </figure>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Separated design for Binary.</figcaption>
    </figure>
    <div class="light-grey col-lg-8 offset-lg-2 pad-20">
      <h4>
        User testing insights that helped inform this design:
      </h4>
      <p>
        <ul>
          <li>The arrows for speed and lane made people think of reverse instead of slow down, and lane change or turn instead of in-lane adjustment.</li>
          <li>The visuals on the Realistic model made people think they just need to tap to complete actions.</li>
          <li>The physical ridges on the Abstract design were confusing and did not add any value.</li>
        </ul>
      </p>
    </div>

  </div>

  <div class="row inner-row">

    <h5 style="padding-top: 15px">Design</h5>
    <p>
      In this iteration, we kept the same concepts from the previous Realistic and Abstract tests, but changed the visuals and abandoned the physical ridges in the Abstract design.  The team experimented with a less literal visual representation for both designs to focus on whether users responded better to a control layout with separate sections for speed and in-lane adjustment (Separated design), or a more centralized, joystick-like control (Consolidated design), without the factor of easier identification of the Realistic design functions in the previous iteration.  We also updated the visuals for the secondary screens, maintaining the same concepts that we hadn’t received sufficient feedback on yet.
    </p>
    <h5>Protocol</h5>
    <p>
      We had users complete the same actions as the last iteration in the same simulator environment.  This entailed asking about affordances; having them adjust speed, change lane position, and confirm a binary decision; and ending with asking about the S curve vs. a flat screen.
    </p>
    <ul>
      <li>8/9 knew what to do for the Consolidated design after being shown how to properly complete the Separated design</li>
      <li>6/9 questioned the necessity of the long arm movement for binary</li>
      <li>6/9 thought pressing on the egg in the center of the Consolidated design would do something</li>
      <li>6/9 liked and understood the Separated design better</li>
      <li>5/9 wanted more information in general about feedback and system status</li>
      <li>5/9 pressed the circle in the Separated design instead of swipe (before direction)</li>
    </ul>
  </div>
  <hr/>
  <div class="row inner-row" id="digital_ut">
    <h2>Digital Interaction User Testing</h2>
    <h3>Edge and Center Designs | 7 Craigslist recruits with driving experience</h3>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Hella Gifs.</figcaption>
    </figure>
    <div class="light-grey col-lg-8 offset-lg-2 pad-20">
      <h4>
        User testing insights that helped inform this design:
      </h4>
      <p>
        <ul>
          <li>Users liked and understood how to use the control better when there were separate sections for speed and lane adjustment, as opposed to a central control that could move in four directions.</li>
          <li>People still didn’t see why they needed to move their arm so much for binary.</li>
          <li>The physical egg made users think a protrusion would actually be on the touch screen control, instead of just responding in that same manner digitally.</li>
          <li>Users still wanted more information about the context of speed and lane adjustment maneuvers, and labels on the control.</li>
        </ul>
      </p>
    </div>
  </div>

  <div class="row inner-row">
    <h5 style="padding-top: 15px">Design</h5>
    <p>
      From the previous iteration, we learned that we should stick with something resembling the Separated design instead of the Consolidated design because users understood it better.  We also made sure to reduce arm movement required for binary decisions, add more labels to the control, and tweak the language on the monitor to provide stronger feedback and more information to the user about the outcome of their hand actions.  We continued with one design that maintained the same structure as our Separated design which allowed users to adjust speed or lane position anywhere within the general area of the label (Center design), and experimented with another design that required pulling with broad strokes across specific activation zones, balancing intentionality with freedom from precise movement (Edge design).  We again had the same binary design for each, but tried a new visual way of representing the swipe affordance - making the nebulous shapes touch.
    </p>
    <h5>Protocol Tech</h5>
    <p>
      For this set of designs, we began testing them digitally on a flat iPad in our simulation set-up.  We also created animations that reflected the user’s touch, and showed confirmation on the control that the user had confirmed a binary decision.
    </p>
    <h5>Protocol Questions</h5>
    <p>
      Users were again asked the same types of questions from previous protocols, but were also specifically asked what they thought of the secondary screen, and also if this way of controlling the autonomous vehicle was better than taking over completely (manual driving).  Also, half of the participants were shown the Edge design first, and half shown the Center design first, to eliminate any effects of knowing how to do one before exposure to the other.  Finally, users were also shown an alternate set of secondary visuals at the very end of the test for their open input and comparison to the previous design.
    </p>
    <h5>Findings</h5>
  </div>

  <div class="row inner-row">
    <p>
      Edge Design:
    </p>
  </div>
  
  <div class="row inner-row">    
    <ul>
      <li>Users unanimously did not understand the pulling strokes from the edges of the control</li>
      <li>6/7 did not understand “lane adjust” as moving within a lane, as opposed to between lanes</li>
      <li>4/7 tapped the bumpers instead of pulling on them</li>
    </ul>
  </div>
  
  <div class="row inner-row">
    <p>
      Center Design:
    </p>
    <ul>
      <li>Users unanimously preferred the Center design to the Edge design</li>
      <li>Users unanimously performed the intended interaction for speed, regardless of which design they were shown first</li>
      <li>Users unanimously understood swiping left/right to adjust in-lane (aside from confusion about the meaning of “lane adjust” on the control)</li>
      <li>3/7 thought the bars indicated the number of fingers required for the interaction</li>
      <li>3/7 appreciated fewer options on the screen</li>
    </ul>

    <p>
      Binary Decision:
    </p>
    <ul>
      <li>6/7 thought tapping the bottom shape would confirm the prompt</li>
      <li>4/7 thought the open black space was an input area for tapping or tracing a path</li>
      <li>3/7 wanted to confirm the prompt by completing an action incorporating the direction of the turn (like confirming a right turn on red by tracing a right turn path in the black area)</li>
    </ul>

    <p>
      Secondary Monitor:
    </p>
    <ul>
      <li>Users split between whether or not the car icon was helpful in the alternate screen design</li>
      <li>Half of the users were confused about what the circular shapes for the in-lane adjustment screen meant (some thought they indicated movement, or speed, or space creation on that side)</li>
    </ul>

    <p>
      Miscellaneous and Broader Insights:
    </p>
    <ul>
      <li>Consensus on our control being better than takeover</li>
      <li>Users want to tap any complete shape that might be a button</li>
      <li>Those who want a more minimal design understand the control and its use, while those that ask for more detailed information seem to need more clarification on the value of the control</li>
      <li>Understanding the translation of hand/arm movement to car movement is linked to how a user perceived the car in its environment</li>
      <ul>
        <li>If someone perceives the car as an object in space, they understand what is happening better and more easily</li>
        <li>If someone is looking at the control as a means of steering a mechanical object, it is more difficult for them to understand how to use the control</li>
      </ul>
    </ul>
  </div>
  <div class="row inner-row">
    <h3>New Center Design | 7 Tesla Autopilot users, 7 Craigslist recruits with (regular) driving experience</h3>
    <figure class="figure">
      <img src="images/micro.png" class="img-fluid" alt="Responsive image">
      <figcaption class="figure-caption">Hella Gifs of Designs.</figcaption>
    </figure>

    <div class="light-grey col-lg-8 offset-lg-2 pad-20">
      <h4>
        User testing insights that helped inform this design:
      </h4>
      <p>
        <ul>
          <li>The Center design was vastly more successful and understandable, allowing most users to perform the speed and lane adjustment maneuvers correctly without guidance.</li>
          <li>The binary design needs to be adjusted so that it does not look like an open input area, and still encourages the swipe motion.</li>
          <li>In-lane adjustment visual for the secondary screen needs to be altered so it does not reflect space being created on the side one is moving towards.</li>
          <li>Any complete shape looks like a button.</li>
        </ul>
      </p>
    </div>
  </div>

  <div class="row inner-row">
    <h5 style="padding-top: 15px">Design</h5>
    <p>
      In the New Center design, the speed and lane adjust screens were kept the same as they were in the Center design previously as it was largely successful.  The binary screen was changed to have a new kind of visual affordance and feedback reminiscent of blinds, eliminating the dark center area and labeling the two options on the control itself.  A “wave and fill” metaphor was leveraged for the new speed display on the secondary screen, showing target speed being set and the progress toward that target speed.  In-lane adjustment was also altered, placing a car icon on a string that resembled the wave from the speed screen, stretching to the left or right direction instead of trying to show arrows or shapes to the side of the vehicle (this was to minimize the impression that space was being created on that side of the car).  Finally, the binary display on the secondary screen also used the “wave and fill” motif to reflect the visuals on the control for binary, and to show the progress of confirmation.
    </p>

    <h5>Protocol Tech</h5>
    <p>
      For this iteration, we put together a system for testing our digital designs on an interactive curved surface instead of a flat tablet.  This involved a plexiglass curve on top of a projector with an attached infrared camera to track user hand movements through the plexiglass, triggering feedback on the screen and changes in the secondary screen and simulator (such as having the simulator increase in speed as the user swipes up on the control).  See [Testing Environment] for more details on the testing apparatus and simulation set-up.
    </p>

    <h5>Protocol Questions</h5>
    <p>
      In the protocol, users were asked to complete the same tasks as recent iterations (affordances, speed, in-lane adjustment, a binary decision, their input on the secondary screen, and thoughts on our intended interaction patterns).  However, in this test, the binary decision was changed from a right on red to passing a bus in order to learn more about user impressions of a different binary situation.  Also, we added extra questions at the end to get some broader input about the concept, including questions about other use cases they would like addressed, and questions for Tesla drivers about when they’ve taken over from Tesla Autopilot before and how our control compares to the controls available to them in their vehicle now.
    </p>

    <h5>Findings</h5>
  </div>
  <div class="row inner-row">
    <p>
      Speed
      <ul>
        <li>All users except one performed the expected interaction for speed</li>
        <li>10/14 users expected speed to begin changing as soon as they started moving their hand on the speed portion of the control</li>
        <li>About half of users understood the meaning and value of the “wave and fill” graphic on the speed display on the secondary screen</li>
      </ul>
    </p>
    <p>
      In-lane Adjustment:
      <ul>
        <li>About half of users understood that the lane adjustment was about moving within a lane, not between lanes</li>
        <li>“Nudge in lane” was seen as appropriate but some but odd by many - it became clear that it should be changed to “Adjust in Lane” on the control and screen</li>
        <li>A few users tried to move side to side in the speed area of the control instead of the bottom area</li>
        <li>6 Tesla drivers and 2 other users wanted more information about the real-life road conditions in the lane adjustment secondary screen (we suspect this has to do with the way Tesla expresses surroundings in their dashboard)</li>
      </ul>
    </p>

    <p>
      Binary:
  </div>
  <div class="row inner-row">
      <br/>
      <ul>
        <li>About half of users voiced and appreciated the benefits of the binary swipe instead of a button press</li>
        <li>Half of users tried to tap the word to confirm instead of swipe</li>
        <li>A few users swiped up on the control without guidance</li>
        <li>“Hang back” was soon as too casual or ambiguous by most - will change to “Dismiss”</li>
      </ul>
    </p>
  </div>
  <div class="row inner-row">
    <p>
      Miscellaneous:
      <ul>
        <li>9/14 mentioned wanting an emergency stop function (3 Tesla drivers, 6 other users)</li>
        <li>A few users felt the secondary screen was too far to the right in their field of vision (location in instrument cluster or heads-up display would be better)</li>
        <li>A few users mentioned that having the same motion for speeding up and confirming binary actions was a good thing</li>
      </ul>
    </p>
  </div>
  <div class="row inner-row">
    <a href="#top">Back to Top</a>
  </div>
  </div>

  </div>
</div>
</body>
<footer class="footer">
  <div class="container text-center">
    <span class="text-muted">2018 MHCI Capstone</span>
  </div>
</footer>
<script>
  var scroll = new SmoothScroll('a[href*="#"]');
</script>
</html>
